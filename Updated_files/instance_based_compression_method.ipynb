{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import string\n",
    "from scipy import sparse\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import bz2\n",
    "import gzip\n",
    "import zlib\n",
    "#import lzw3\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lzma\n",
    "from sklearn.metrics import classification_report\n",
    "import pyppmd\n",
    "#import ppmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "all_instances={\n",
    "\n",
    "    'hrudayashiva':[\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",10,11,12],\n",
    "    'ravibeliger':[13,14,15,16,17,18,19,20,21,22,23,24,25],\n",
    "    'somashaker':[26,27,28,29,30,31,32,33,34,35,36,37],\n",
    "    'chandrashekark':[38,39,40,41,42,43,44,45,46,47],\n",
    "    'usha':[48,49,50,51,52,53,54,55,56,57,58,59,60],\n",
    "    'bhagavan':[61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76],\n",
    "    'NaDisoza':[77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103],\n",
    "    'srinatha':[104,105,106,107,108,109,110,111],\n",
    "    'gatti':[112,113,114,115,116,117,118,119,120],\n",
    "    'dodderi':[126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151],\n",
    "    'Bhadrannavar':[152,153,154,155,156,157,158,159],\n",
    "    'Narsimhamurthy':[160,161,162,163,164,165,166,167],\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_list = \"C://Users/RAVIKUMAR/PycharmProjects/Authorship_Attribution_Instance/Data_2/new_stop_words.txt\"\n",
    "stop_words_list = \"C://Users/Muniraju B N/Desktop/Authorship-Attribution-Compression_method-main/Datasets/new_stop_words.txt\"\n",
    "data_folder = \"C://Users/Muniraju B N/Desktop/Authorship-Attribution-Compression_method-main/instance gen_data - Copy\"\n",
    "instance_by_author={}\n",
    "for author,AllFiles_Per_author in all_instances.items():\n",
    "    for i in AllFiles_Per_author:\n",
    "        #try:\n",
    "            for name in glob.glob(f\"C://Users/Muniraju B N/Desktop/Authorship-Attribution-Compression_method-main/instance gen_data - Copy/instances{(i)}.txt\"):\n",
    "                #with open(name, encoding='utf-8') as file:\n",
    "                with open(name,encoding='utf-8') as file:\n",
    "                    instance_by_author[author+str(i)]=file.read()\n",
    "        #except:\n",
    "            #pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instance_by_author.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword=[]\n",
    "\n",
    "with open(stop_words_list, encoding='utf-8') as file:\n",
    "    reader=file.read()\n",
    "    reader = [reader.split()]\n",
    "    stopword = sum(reader, [])\n",
    "def text_process(text):\n",
    "    nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(nopunct)\n",
    "    nopunct = \" \".join([word for word in tokens if word not in stopword])\n",
    "    return nopunct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display loaded data for compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors with id</th>\n",
       "      <th>text files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>Narsimhamurthy163</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>Narsimhamurthy164</td>\n",
       "      <td>\\n\\nಚಲನಚಿತ್ರ ಮತ್ತು ಟಿ.ವಿ. ಧಾರಾವಾಹಿಗಳಲ್ಲಿನ ಬಹುಮ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>Narsimhamurthy165</td>\n",
       "      <td>\\n                               ಭೈರಪ್ಪನವರ ಕೃತ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>Narsimhamurthy166</td>\n",
       "      <td>ಮಡಿವಾಳ ಮಾಚಿದೇವ - Madiwala Machideva\\nಮಡಿವಾಳ ಮಾ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>Narsimhamurthy167</td>\n",
       "      <td>ಶರಣೆ ದಾನಮ್ಮ - Sharane Danamma\\nಶರಣೆ ದಾನಮ್ಮ\\nತಾ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Authors with id                                         text files\n",
       "157  Narsimhamurthy163                                                ...\n",
       "158  Narsimhamurthy164  \\n\\nಚಲನಚಿತ್ರ ಮತ್ತು ಟಿ.ವಿ. ಧಾರಾವಾಹಿಗಳಲ್ಲಿನ ಬಹುಮ...\n",
       "159  Narsimhamurthy165  \\n                               ಭೈರಪ್ಪನವರ ಕೃತ...\n",
       "160  Narsimhamurthy166  ಮಡಿವಾಳ ಮಾಚಿದೇವ - Madiwala Machideva\\nಮಡಿವಾಳ ಮಾ...\n",
       "161  Narsimhamurthy167  ಶರಣೆ ದಾನಮ್ಮ - Sharane Danamma\\nಶರಣೆ ದಾನಮ್ಮ\\nತಾ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_authors=[]\n",
    "text=[]\n",
    "original = pd.DataFrame()\n",
    "for author, file in instance_by_author.items():\n",
    "    all_authors.append(author)\n",
    "    text.append(file)\n",
    "    \n",
    "original[\"Authors with id\"] = all_authors\n",
    "original[\"text files\"]=text\n",
    "original.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = pd.Series(original[\"Authors with id\"])\n",
    "# Y.replace(r'(^ra.*)','Ravibeligeri',regex=True, inplace = True)\n",
    "# Y.replace(r'(^hr.*)','Hrudayashiva',regex=True, inplace = True)\n",
    "# Y.replace(r'(^som.*)','Somashaker',regex=True, inplace = True)\n",
    "# Y.replace(r'(^ch.*)', 'Chandrashekar_k', regex=True, inplace=True)\n",
    "# Y.replace(r'(^ush.*)', 'Usha', regex=True, inplace=True)\n",
    "# Y.replace(r'(^bha.*)', 'Bhagavan', regex=True, inplace=True)\n",
    "# Y.replace(r'(^Na.*)', 'NaDisoza', regex=True, inplace=True)\n",
    "# Y.replace(r'(^sri.*)', 'Srinatha', regex=True, inplace=True)\n",
    "# Y.replace(r'(^gat.*)', 'gatti', regex=True, inplace=True)\n",
    "# Y.replace(r'(^dod.*)', 'dodderi', regex=True, inplace=True)\n",
    "# Y.replace(r'(^badr.*)', 'Bhadrannavar', regex=True, inplace=True)\n",
    "# Y.replace(r'(^nar.*)', 'Narsimhamurthy', regex=True, inplace=True)\n",
    "# Y.replace(r'(^ram.*)', 'Ramesh', regex=True, inplace=True)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text']=text\n",
    "#df[\"Authors\"] = Y\n",
    "#y = df[\"Authors\"]\n",
    "X=df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hrudayashiva01',\n",
       " 'hrudayashiva02',\n",
       " 'hrudayashiva03',\n",
       " 'hrudayashiva04',\n",
       " 'hrudayashiva05',\n",
       " 'hrudayashiva06',\n",
       " 'hrudayashiva07',\n",
       " 'hrudayashiva08',\n",
       " 'hrudayashiva09',\n",
       " 'hrudayashiva10',\n",
       " 'hrudayashiva11',\n",
       " 'hrudayashiva12',\n",
       " 'ravibeliger13',\n",
       " 'ravibeliger14',\n",
       " 'ravibeliger15',\n",
       " 'ravibeliger16',\n",
       " 'ravibeliger17',\n",
       " 'ravibeliger18',\n",
       " 'ravibeliger19',\n",
       " 'ravibeliger20',\n",
       " 'ravibeliger21',\n",
       " 'ravibeliger22',\n",
       " 'ravibeliger23',\n",
       " 'ravibeliger24',\n",
       " 'ravibeliger25',\n",
       " 'somashaker26',\n",
       " 'somashaker27',\n",
       " 'somashaker28',\n",
       " 'somashaker29',\n",
       " 'somashaker30',\n",
       " 'somashaker31',\n",
       " 'somashaker32',\n",
       " 'somashaker33',\n",
       " 'somashaker34',\n",
       " 'somashaker35',\n",
       " 'somashaker36',\n",
       " 'somashaker37',\n",
       " 'chandrashekark38',\n",
       " 'chandrashekark39',\n",
       " 'chandrashekark40',\n",
       " 'chandrashekark41',\n",
       " 'chandrashekark42',\n",
       " 'chandrashekark43',\n",
       " 'chandrashekark44',\n",
       " 'chandrashekark45',\n",
       " 'chandrashekark46',\n",
       " 'chandrashekark47',\n",
       " 'usha48',\n",
       " 'usha49',\n",
       " 'usha50',\n",
       " 'usha51',\n",
       " 'usha52',\n",
       " 'usha53',\n",
       " 'usha54',\n",
       " 'usha55',\n",
       " 'usha56',\n",
       " 'usha57',\n",
       " 'usha58',\n",
       " 'usha59',\n",
       " 'usha60',\n",
       " 'bhagavan61',\n",
       " 'bhagavan62',\n",
       " 'bhagavan63',\n",
       " 'bhagavan64',\n",
       " 'bhagavan65',\n",
       " 'bhagavan66',\n",
       " 'bhagavan67',\n",
       " 'bhagavan68',\n",
       " 'bhagavan69',\n",
       " 'bhagavan70',\n",
       " 'bhagavan71',\n",
       " 'bhagavan72',\n",
       " 'bhagavan73',\n",
       " 'bhagavan74',\n",
       " 'bhagavan75',\n",
       " 'bhagavan76',\n",
       " 'NaDisoza77',\n",
       " 'NaDisoza78',\n",
       " 'NaDisoza79',\n",
       " 'NaDisoza80',\n",
       " 'NaDisoza81',\n",
       " 'NaDisoza82',\n",
       " 'NaDisoza83',\n",
       " 'NaDisoza84',\n",
       " 'NaDisoza85',\n",
       " 'NaDisoza86',\n",
       " 'NaDisoza87',\n",
       " 'NaDisoza88',\n",
       " 'NaDisoza89',\n",
       " 'NaDisoza90',\n",
       " 'NaDisoza91',\n",
       " 'NaDisoza92',\n",
       " 'NaDisoza93',\n",
       " 'NaDisoza94',\n",
       " 'NaDisoza95',\n",
       " 'NaDisoza96',\n",
       " 'NaDisoza97',\n",
       " 'NaDisoza98',\n",
       " 'NaDisoza99',\n",
       " 'NaDisoza100',\n",
       " 'NaDisoza101',\n",
       " 'NaDisoza102',\n",
       " 'NaDisoza103',\n",
       " 'srinatha104',\n",
       " 'srinatha105',\n",
       " 'srinatha106',\n",
       " 'srinatha107',\n",
       " 'srinatha108',\n",
       " 'srinatha109',\n",
       " 'srinatha110',\n",
       " 'srinatha111',\n",
       " 'gatti112',\n",
       " 'gatti113',\n",
       " 'gatti114',\n",
       " 'gatti115',\n",
       " 'gatti116',\n",
       " 'gatti117',\n",
       " 'gatti118',\n",
       " 'gatti119',\n",
       " 'gatti120',\n",
       " 'dodderi126',\n",
       " 'dodderi127',\n",
       " 'dodderi128',\n",
       " 'dodderi129',\n",
       " 'dodderi130',\n",
       " 'dodderi131',\n",
       " 'dodderi132',\n",
       " 'dodderi133',\n",
       " 'dodderi134',\n",
       " 'dodderi135',\n",
       " 'dodderi136',\n",
       " 'dodderi137',\n",
       " 'dodderi138',\n",
       " 'dodderi139',\n",
       " 'dodderi140',\n",
       " 'dodderi141',\n",
       " 'dodderi142',\n",
       " 'dodderi143',\n",
       " 'dodderi144',\n",
       " 'dodderi145',\n",
       " 'dodderi146',\n",
       " 'dodderi147',\n",
       " 'dodderi148',\n",
       " 'dodderi149',\n",
       " 'dodderi150',\n",
       " 'dodderi151',\n",
       " 'Bhadrannavar152',\n",
       " 'Bhadrannavar153',\n",
       " 'Bhadrannavar154',\n",
       " 'Bhadrannavar155',\n",
       " 'Bhadrannavar156',\n",
       " 'Bhadrannavar157',\n",
       " 'Bhadrannavar158',\n",
       " 'Bhadrannavar159',\n",
       " 'Narsimhamurthy160',\n",
       " 'Narsimhamurthy161',\n",
       " 'Narsimhamurthy162',\n",
       " 'Narsimhamurthy163',\n",
       " 'Narsimhamurthy164',\n",
       " 'Narsimhamurthy165',\n",
       " 'Narsimhamurthy166',\n",
       " 'Narsimhamurthy167']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()\n",
    "compFiles = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, all_authors,test_size=0.3, random_state=3552)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression technieques:\n",
    "compressed text files in bytes\n",
    "<h1>\n",
    "* Lzma <br>\n",
    "* bzip <br>\n",
    "* gzip <br>\n",
    "* zip <br>\n",
    "* PPM\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instances - training and testing -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Author_and_file={}\n",
    "\n",
    "x_y={}\n",
    "for (i, j ) in zip(y_train, X_train):\n",
    "    Author_and_file[i] = j\n",
    "\n",
    "# testing files\n",
    "# singleFile=\"\"\n",
    "# singleAuthor=\"\"\n",
    "A=list(X_test)\n",
    "B=list(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"original author: \", singleAuthor)\n",
    "# print(\"file content\", singleFile)\n",
    "df3=pd.DataFrame()\n",
    "df3[\"author\"]=B\n",
    "df3[\"file\"]=A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = lzma.compress(bytes(A[0], 'utf-16'))\n",
    "# d = lzma.decompress(c).decode('utf-16')\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Normalized Compressor Distance (NCD) <center>\n",
    "It uses general compressors to estimate the amount of shared\n",
    "information between two objects. The Normalized\n",
    "Compression Distance is defined as:\n",
    "\n",
    "$$\n",
    " NCD(x/y) = \\frac{\\ C(x/y)-min(C(x),C(y))}{max(C(x),C(y))}\n",
    "$$\n",
    "\n",
    "Where C(x) is the size of the compressed object x. If x = y,\n",
    "the NCD is approximately 0, as the full string y can be\n",
    "described in terms of previous strings found in x; if x and y\n",
    "share no common information the NCD is 1 + e, where e is a\n",
    "small quantity due to imperfections characterizing real\n",
    "compressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       1.00      1.00      1.00         5\n",
      "chandrashekark       1.00      0.50      0.67         2\n",
      "       dodderi       0.64      0.88      0.74         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       0.60      0.75      0.67         4\n",
      "   ravibeliger       0.75      0.60      0.67         5\n",
      "    somashaker       1.00      0.60      0.75         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       0.80      0.80      0.80         5\n",
      "\n",
      "      accuracy                           0.84        49\n",
      "     macro avg       0.90      0.84      0.86        49\n",
      "  weighted avg       0.86      0.84      0.84        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lzma_truValues=[]\n",
    "lzma_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n]\n",
    "    \n",
    "    lzma_concat = {}\n",
    "    lzma_concat_comp ={}\n",
    "    lzma_compress_train={} \n",
    "\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in Author_and_file.items():\n",
    "        lzma_compress_train[author] = lzma.compress(bytes(data, 'utf-8'))\n",
    "        lzma_concat[author] = data+singleFile\n",
    "\n",
    "    #compress single file for testing     \n",
    "    lzma_singleFileComp = lzma.compress(bytes(singleFile, 'utf-8'))\n",
    "#     decomLzma= lzma.decompress(bytes(lzma_singleFileComp))\n",
    "#     print(decomLzma)\n",
    "\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in lzma_concat.items():\n",
    "        lzma_concat_comp[i] = lzma.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    #calculate ncd values for each instance\n",
    "    lzma_ncd_values={}\n",
    "    for i,j in lzma_compress_train.items():\n",
    "        lzma_ncd_values[i] = (len(lzma_concat_comp[i]) - min(len(lzma_compress_train[i]), len(lzma_singleFileComp)))/max(len(lzma_compress_train[i]), len(lzma_singleFileComp))\n",
    "    \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])\n",
    "    lzma_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(lzma_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    lzma_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(lzma_truValues, lzma_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       1.00      1.00      1.00         5\n",
      "chandrashekark       1.00      1.00      1.00         2\n",
      "       dodderi       0.73      1.00      0.84         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       1.00      0.75      0.86         4\n",
      "   ravibeliger       0.75      0.60      0.67         5\n",
      "    somashaker       1.00      0.80      0.89         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       1.00      1.00      1.00         5\n",
      "\n",
      "      accuracy                           0.92        49\n",
      "     macro avg       0.96      0.93      0.94        49\n",
      "  weighted avg       0.93      0.92      0.92        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bzip_truValues=[]\n",
    "\n",
    "bzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    bzip_compress_train={}\n",
    "    bzip_concat={}\n",
    "    bzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in Author_and_file.items():\n",
    "        bzip_compress_train[author] = bz2.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        bzip_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #compress single file for testing   \n",
    "    bzip_singleFileComp = bz2.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in bzip_concat.items():\n",
    "        bzip_concat_comp[i] = bz2.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    bzip_ncd_values={}\n",
    "    for i,j in bzip_compress_train.items():\n",
    "        bzip_ncd_values[i] = (len(bzip_concat_comp[i]) - min(len(bzip_compress_train[i]), len(bzip_singleFileComp)))/max(len(bzip_compress_train[i]), len(bzip_singleFileComp))\n",
    "    #print(\"correct author:\",singleAuthor[:-2])\n",
    "   \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])\n",
    "    bzip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(bzip_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    bzip_truPred.append(pred)\n",
    "    #print(\"Predicted:\",tp)\n",
    "    #print()\n",
    "print(classification_report(bzip_truValues, bzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      0.50      0.67         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       0.83      1.00      0.91         5\n",
      "chandrashekark       1.00      0.50      0.67         2\n",
      "       dodderi       0.78      0.88      0.82         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       0.75      0.75      0.75         4\n",
      "   ravibeliger       0.80      0.80      0.80         5\n",
      "    somashaker       1.00      0.80      0.89         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       0.83      1.00      0.91         5\n",
      "\n",
      "      accuracy                           0.88        49\n",
      "     macro avg       0.92      0.85      0.87        49\n",
      "  weighted avg       0.89      0.88      0.87        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gzip_truValues=[]\n",
    "gzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    gzip_compress_train={}\n",
    "    gzip_concat={}\n",
    "    gzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in Author_and_file.items():\n",
    "        gzip_compress_train[author] = gzip.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        gzip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    gzip_singleFileComp = gzip.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in gzip_concat.items():\n",
    "        gzip_concat_comp[i] = gzip.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    gzip_ncd_values={}\n",
    "    for i,j in gzip_compress_train.items():\n",
    "        gzip_ncd_values[i] = (len(gzip_concat_comp[i]) - min(len(gzip_compress_train[i]), len(gzip_singleFileComp)))/max(len(gzip_compress_train[i]), len(gzip_singleFileComp))\n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])    \n",
    "    gzip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(gzip_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    gzip_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(gzip_truValues, gzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       1.00      1.00      1.00         5\n",
      "chandrashekark       1.00      0.50      0.67         2\n",
      "       dodderi       0.73      1.00      0.84         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       1.00      0.25      0.40         4\n",
      "   ravibeliger       0.43      0.60      0.50         5\n",
      "    somashaker       1.00      0.60      0.75         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       0.83      1.00      0.91         5\n",
      "\n",
      "      accuracy                           0.84        49\n",
      "     macro avg       0.92      0.83      0.84        49\n",
      "  weighted avg       0.88      0.84      0.83        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_truValues=[]\n",
    "zip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    zip_compress_train={}\n",
    "    zip_concat={}\n",
    "    zip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    for author, data in Author_and_file.items():\n",
    "        zip_compress_train[author] = zlib.compress(bytes(data, 'utf-8'))    \n",
    "        #file concatination\n",
    "        zip_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #test file compress    \n",
    "    zip_singleFileComp = zlib.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in zip_concat.items():\n",
    "        zip_concat_comp[i] = zlib.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    zip_ncd_values={}\n",
    "    for i,j in zip_compress_train.items():\n",
    "        zip_ncd_values[i] = (len(zip_concat_comp[i]) - min(len(zip_compress_train[i]), len(zip_singleFileComp)))/max(len(zip_compress_train[i]), len(zip_singleFileComp))\n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])    \n",
    "    zip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(zip_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    zip_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(zip_truValues, zip_truPred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       1.00      1.00      1.00         5\n",
      "chandrashekark       1.00      0.50      0.67         2\n",
      "       dodderi       0.78      0.88      0.82         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       0.67      1.00      0.80         4\n",
      "   ravibeliger       1.00      0.80      0.89         5\n",
      "    somashaker       1.00      1.00      1.00         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       1.00      0.80      0.89         5\n",
      "\n",
      "      accuracy                           0.92        49\n",
      "     macro avg       0.95      0.91      0.92        49\n",
      "  weighted avg       0.94      0.92      0.92        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppm_truValues=[]\n",
    "ppm_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    ppm_compress_train={}\n",
    "    ppm_concat={}\n",
    "    ppm_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    for author, data in Author_and_file.items():\n",
    "        ppm_compress_train[author] = pyppmd.compress(bytes(data, 'utf-8'))    \n",
    "        #file concatination\n",
    "        ppm_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #test file compress    \n",
    "    ppm_singleFileComp = pyppmd.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in ppm_concat.items():\n",
    "        ppm_concat_comp[i] = pyppmd.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    ppm_ncd_values={}\n",
    "    for i,j in ppm_compress_train.items():\n",
    "        ppm_ncd_values[i] = (len(ppm_concat_comp[i]) - min(len(ppm_compress_train[i]), len(ppm_singleFileComp)))/max(len(ppm_compress_train[i]), len(ppm_singleFileComp))\n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    ppm_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(ppm_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    ppm_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(ppm_truValues, ppm_truPred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>Conditional Complexity of Compression (CCC)</center></h1><br>\n",
    "\n",
    "Conditional Complexity of Compression (CCC) proposed in The CCC of text y given text x is calculated by\n",
    "$$\n",
    "CCC(y/x) = |Sc|-|Xc|\n",
    "$$\n",
    "where <b>|xc| is the length of the compressed text x <br>\n",
    "The S is the concatenated text of xy</b><br>\n",
    "\n",
    "CCC approximates a more abstract\n",
    "Kolmogorov conditional complexity and measures adapts to\n",
    "patterns in the training text for better compressing the\n",
    "unknown text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      0.75      0.86         8\n",
      "Narsimhamurthy       0.07      1.00      0.12         1\n",
      "      bhagavan       1.00      1.00      1.00         5\n",
      "chandrashekark       0.00      0.00      0.00         2\n",
      "       dodderi       0.00      0.00      0.00         8\n",
      "         gatti       0.14      1.00      0.25         2\n",
      "  hrudayashiva       0.00      0.00      0.00         4\n",
      "   ravibeliger       0.00      0.00      0.00         5\n",
      "    somashaker       0.00      0.00      0.00         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       0.80      0.80      0.80         5\n",
      "\n",
      "      accuracy                           0.45        49\n",
      "     macro avg       0.42      0.55      0.42        49\n",
      "  weighted avg       0.44      0.45      0.42        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import m2-liblzma\n",
    "#import xz utils\n",
    "import py7zr\n",
    "import lzma as xz\n",
    "#import liblzma\n",
    "\n",
    "lzma_truValues=[]\n",
    "lzma_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n]\n",
    "    \n",
    "    lzma_concat = {}\n",
    "    lzma_concat_comp ={}\n",
    "    lzma_compress_train={} \n",
    "\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in Author_and_file.items():\n",
    "        lzma_compress_train[author] = xz.compress(bytes(data, 'utf-8'))\n",
    "        #lzma_compress_train[author] = lzma.LZMACompressor(bytes(data,\"utf-8\"), format='.xz', check=-1,preset=None, )\n",
    "        lzma_concat[author] = data+singleFile\n",
    "\n",
    "        \n",
    "    #compress single file for testing  \n",
    "    lzma_singleFileComp = xz.compress(bytes(singleFile, 'utf-8'))\n",
    "    #lzma_singleFileComp = lzma.LZMACompressor(bytes(singleFile,\"utf-8\"),format='.xz', check=-1 )\n",
    "#     decomLzma= lzma.decompress(bytes(lzma_singleFileComp))\n",
    "#     print(decomLzma)\n",
    "\n",
    "    #FORMAT_XZ= '.xz'\n",
    "    #compress concatinated file \n",
    "    for i,j in lzma_concat.items():\n",
    "        lzma_concat_comp[i] = xz.compress(bytes(j, \"utf-8\"))\n",
    "        #lzma_concat_comp[i] = lzma.LZMACompressor(bytes(j,\"utf-8\"),format='.xz', check=-1)\n",
    "\n",
    "\n",
    "    #calculate ncd values for each instance\n",
    "    lzma_ccc_values={}\n",
    "    for i,j in lzma_compress_train.items():\n",
    "        lzma_ccc_values[i] = (len(lzma_concat_comp[i]) - len(lzma_compress_train[i]))\n",
    "    \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    lzma_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(lzma_ccc_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    lzma_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(lzma_truValues, lzma_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       0.89      1.00      0.94         8\n",
      "Narsimhamurthy       0.11      1.00      0.20         1\n",
      "      bhagavan       0.56      1.00      0.71         5\n",
      "chandrashekark       1.00      0.50      0.67         2\n",
      "       dodderi       1.00      0.25      0.40         8\n",
      "         gatti       0.29      1.00      0.44         2\n",
      "  hrudayashiva       0.00      0.00      0.00         4\n",
      "   ravibeliger       0.00      0.00      0.00         5\n",
      "    somashaker       1.00      0.20      0.33         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       0.71      1.00      0.83         5\n",
      "\n",
      "      accuracy                           0.59        49\n",
      "     macro avg       0.63      0.66      0.54        49\n",
      "  weighted avg       0.68      0.59      0.54        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bzip_truValues=[]\n",
    "\n",
    "bzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    bzip_compress_train={}\n",
    "    bzip_concat={}\n",
    "    bzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in Author_and_file.items():\n",
    "        bzip_compress_train[author] = bz2.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        bzip_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #compress single file for testing   \n",
    "    bzip_singleFileComp = bz2.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in bzip_concat.items():\n",
    "        bzip_concat_comp[i] = bz2.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    # calculate ccc values\n",
    "    bzip_ccc_values={}\n",
    "    for i,j in bzip_compress_train.items():\n",
    "        bzip_ccc_values[i] = (len(bzip_concat_comp[i]) - len(bzip_compress_train[i]))    \n",
    "    \n",
    "    #print(\"correct author:\",singleAuthor[:-2])\n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    bzip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(bzip_ccc_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    bzip_truPred.append(pred)\n",
    "    #print(\"Predicted:\",tp)\n",
    "    #print()\n",
    "print(classification_report(bzip_truValues, bzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       0.89      1.00      0.94         8\n",
      "Narsimhamurthy       0.50      1.00      0.67         1\n",
      "      bhagavan       0.26      1.00      0.42         5\n",
      "chandrashekark       0.00      0.00      0.00         2\n",
      "       dodderi       1.00      0.25      0.40         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       1.00      0.25      0.40         4\n",
      "   ravibeliger       1.00      0.20      0.33         5\n",
      "    somashaker       0.00      0.00      0.00         5\n",
      "      srinatha       0.50      1.00      0.67         2\n",
      "          usha       0.57      0.80      0.67         5\n",
      "\n",
      "      accuracy                           0.57        49\n",
      "     macro avg       0.64      0.62      0.54        49\n",
      "  weighted avg       0.69      0.57      0.52        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gzip_truValues=[]\n",
    "gzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    gzip_compress_train={}\n",
    "    gzip_concat={}\n",
    "    gzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in Author_and_file.items():\n",
    "        gzip_compress_train[author] = gzip.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        gzip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    gzip_singleFileComp = gzip.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in gzip_concat.items():\n",
    "        gzip_concat_comp[i] = gzip.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    gzip_ccc_values={}\n",
    "    for i,j in gzip_compress_train.items():\n",
    "        gzip_ccc_values[i] = (len(gzip_concat_comp[i]) -  len(gzip_compress_train[i]))\n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    gzip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(gzip_ccc_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    gzip_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(gzip_truValues, gzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       0.80      1.00      0.89         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       0.56      1.00      0.71         5\n",
      "chandrashekark       1.00      0.50      0.67         2\n",
      "       dodderi       1.00      0.62      0.77         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       1.00      0.75      0.86         4\n",
      "   ravibeliger       1.00      0.80      0.89         5\n",
      "    somashaker       1.00      0.20      0.33         5\n",
      "      srinatha       0.67      1.00      0.80         2\n",
      "          usha       0.62      1.00      0.77         5\n",
      "\n",
      "      accuracy                           0.80        49\n",
      "     macro avg       0.89      0.82      0.81        49\n",
      "  weighted avg       0.87      0.80      0.78        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_truValues=[]\n",
    "zip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    zip_compress_train={}\n",
    "    zip_concat={}\n",
    "    zip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    for author, data in Author_and_file.items():\n",
    "        zip_compress_train[author] = zlib.compress(bytes(data, 'utf-8'))    \n",
    "        #file concatination\n",
    "        zip_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #test file compress    \n",
    "    zip_singleFileComp = zlib.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in zip_concat.items():\n",
    "        zip_concat_comp[i] = zlib.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    zip_ccc_values={}\n",
    "    for i,j in zip_compress_train.items():\n",
    "        zip_ccc_values[i] = (len(zip_concat_comp[i]) - len(zip_compress_train[i]))\n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])       \n",
    "    zip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(zip_ccc_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    zip_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(zip_truValues, zip_truPred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       0.50      1.00      0.67         1\n",
      "      bhagavan       0.36      1.00      0.53         5\n",
      "chandrashekark       1.00      1.00      1.00         2\n",
      "       dodderi       1.00      0.50      0.67         8\n",
      "         gatti       0.50      1.00      0.67         2\n",
      "  hrudayashiva       0.50      0.25      0.33         4\n",
      "   ravibeliger       1.00      0.20      0.33         5\n",
      "    somashaker       1.00      0.40      0.57         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       0.67      0.80      0.73         5\n",
      "\n",
      "      accuracy                           0.69        49\n",
      "     macro avg       0.79      0.76      0.71        49\n",
      "  weighted avg       0.83      0.69      0.68        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppm_truValues=[]\n",
    "ppm_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    ppm_compress_train={}\n",
    "    ppm_concat={}\n",
    "    ppm_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    for author, data in Author_and_file.items():\n",
    "        ppm_compress_train[author] = pyppmd.compress(bytes(data, 'utf-8'))    \n",
    "        #file concatination\n",
    "        ppm_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #test file compress    \n",
    "    ppm_singleFileComp = pyppmd.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in ppm_concat.items():\n",
    "        ppm_concat_comp[i] = pyppmd.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    ppm_ccc_values={}\n",
    "    for i,j in ppm_compress_train.items():\n",
    "        ppm_ccc_values[i] = (len(ppm_concat_comp[i]) - len(ppm_compress_train[i]))\n",
    "    \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    ppm_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(ppm_ccc_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    ppm_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(ppm_truValues, ppm_truPred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  <center> Compression Dissimilarity Measure (CDM)<center> \n",
    " Compression Dissimilarity Measure (CDM)\n",
    "For documents x and y, the compression dissimilarity\n",
    "measure is defined as:\n",
    "$$\n",
    "CDM (x/y) = [\\frac{C(xy)}{C(x)+C(y)}]\n",
    "$$\n",
    "Where C (x) is the size of the compressed object x, <br>\n",
    "C(y) is the size of the compressed object y,  <br>\n",
    "xy is the concatenation of x and y and  <br>\n",
    "C(xy) is the size of the compressed object xy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       1.00      1.00      1.00         5\n",
      "chandrashekark       1.00      1.00      1.00         2\n",
      "       dodderi       0.86      0.75      0.80         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       0.50      0.50      0.50         4\n",
      "   ravibeliger       0.57      0.80      0.67         5\n",
      "    somashaker       1.00      1.00      1.00         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       1.00      0.80      0.89         5\n",
      "\n",
      "      accuracy                           0.88        49\n",
      "     macro avg       0.91      0.90      0.90        49\n",
      "  weighted avg       0.89      0.88      0.88        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lzma_truValues=[]\n",
    "lzma_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n]\n",
    "    \n",
    "    lzma_concat = {}\n",
    "    lzma_concat_comp ={}\n",
    "    lzma_compress_train={} \n",
    "\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in Author_and_file.items():\n",
    "        lzma_compress_train[author] = lzma.compress(bytes(data, 'utf-8'))\n",
    "        lzma_concat[author] = data+singleFile\n",
    "\n",
    "    #compress single file for testing     \n",
    "    lzma_singleFileComp = lzma.compress(bytes(singleFile, 'utf-8'))\n",
    "#     decomLzma= lzma.decompress(bytes(lzma_singleFileComp))\n",
    "#     print(decomLzma)\n",
    "\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in lzma_concat.items():\n",
    "        lzma_concat_comp[i] = lzma.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    #calculate ncd values for each instance\n",
    "    lzma_cdm_values={}\n",
    "    for i,j in lzma_compress_train.items():\n",
    "        lzma_cdm_values[i] = (  len(lzma_concat_comp[i]) / ( len(lzma_compress_train[i])+len(lzma_singleFileComp)) )\n",
    "    \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    lzma_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(lzma_cdm_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    lzma_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(lzma_truValues, lzma_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      1.00      1.00         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       1.00      1.00      1.00         5\n",
      "chandrashekark       1.00      1.00      1.00         2\n",
      "       dodderi       0.78      0.88      0.82         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       1.00      0.75      0.86         4\n",
      "   ravibeliger       0.50      0.60      0.55         5\n",
      "    somashaker       1.00      1.00      1.00         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       1.00      0.80      0.89         5\n",
      "\n",
      "      accuracy                           0.90        49\n",
      "     macro avg       0.94      0.92      0.93        49\n",
      "  weighted avg       0.91      0.90      0.90        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bzip_truValues=[]\n",
    "\n",
    "bzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    bzip_compress_train={}\n",
    "    bzip_concat={}\n",
    "    bzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in Author_and_file.items():\n",
    "        bzip_compress_train[author] = bz2.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        bzip_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #compress single file for testing   \n",
    "    bzip_singleFileComp = bz2.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in bzip_concat.items():\n",
    "        bzip_concat_comp[i] = bz2.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    # calculate ccc values\n",
    "    bzip_cdm_values={}\n",
    "    for i,j in bzip_compress_train.items():\n",
    "        bzip_cdm_values[i] = (  len(bzip_concat_comp[i]) / ( len(bzip_compress_train[i])+len(bzip_singleFileComp)) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(\"correct author:\",singleAuthor[:-2])\n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    bzip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(bzip_cdm_values.items(), key=lambda item: item[1]))))\n",
    "   \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    bzip_truPred.append(pred)\n",
    "    #print(\"Predicted:\",tp)\n",
    "    #print()\n",
    "print(classification_report(bzip_truValues, bzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       0.00      0.00      0.00         2\n",
      "      NaDisoza       0.78      0.88      0.82         8\n",
      "Narsimhamurthy       0.00      0.00      0.00         1\n",
      "      bhagavan       1.00      0.40      0.57         5\n",
      "chandrashekark       0.40      1.00      0.57         2\n",
      "       dodderi       1.00      0.88      0.93         8\n",
      "         gatti       0.00      0.00      0.00         2\n",
      "  hrudayashiva       0.40      0.50      0.44         4\n",
      "   ravibeliger       0.57      0.80      0.67         5\n",
      "    somashaker       0.83      1.00      0.91         5\n",
      "      srinatha       0.67      1.00      0.80         2\n",
      "          usha       0.80      0.80      0.80         5\n",
      "\n",
      "      accuracy                           0.71        49\n",
      "     macro avg       0.54      0.60      0.54        49\n",
      "  weighted avg       0.69      0.71      0.68        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gzip_truValues=[]\n",
    "gzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    gzip_compress_train={}\n",
    "    gzip_concat={}\n",
    "    gzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in Author_and_file.items():\n",
    "        gzip_compress_train[author] = gzip.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        gzip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    gzip_singleFileComp = gzip.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in gzip_concat.items():\n",
    "        gzip_concat_comp[i] = gzip.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    gzip_cdm_values={}\n",
    "    for i,j in gzip_compress_train.items():\n",
    "        gzip_cdm_values[i] = (  len(gzip_concat_comp[i]) / ( len(gzip_compress_train[i])+len(gzip_singleFileComp)) )\n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    gzip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(gzip_cdm_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    gzip_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(gzip_truValues, gzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       0.00      0.00      0.00         2\n",
      "      NaDisoza       1.00      0.75      0.86         8\n",
      "Narsimhamurthy       0.00      0.00      0.00         1\n",
      "      bhagavan       1.00      0.20      0.33         5\n",
      "chandrashekark       0.33      1.00      0.50         2\n",
      "       dodderi       0.78      0.88      0.82         8\n",
      "         gatti       0.00      0.00      0.00         2\n",
      "  hrudayashiva       0.40      0.50      0.44         4\n",
      "   ravibeliger       0.36      0.80      0.50         5\n",
      "    somashaker       0.80      0.80      0.80         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       0.75      0.60      0.67         5\n",
      "\n",
      "      accuracy                           0.63        49\n",
      "     macro avg       0.54      0.54      0.49        49\n",
      "  weighted avg       0.67      0.63      0.61        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_truValues=[]\n",
    "zip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    zip_compress_train={}\n",
    "    zip_concat={}\n",
    "    zip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    for author, data in Author_and_file.items():\n",
    "        zip_compress_train[author] = zlib.compress(bytes(data, 'utf-8'))    \n",
    "        #file concatination\n",
    "        zip_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #test file compress    \n",
    "    zip_singleFileComp = zlib.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in zip_concat.items():\n",
    "        zip_concat_comp[i] = zlib.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    zip_cdm_values={}\n",
    "    for i,j in zip_compress_train.items():\n",
    "        zip_cdm_values[i] =  (  len(zip_concat_comp[i]) / ( len(zip_compress_train[i])+len(zip_singleFileComp)) )\n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])       \n",
    "    zip_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(zip_cdm_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    zip_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(zip_truValues, zip_truPred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Bhadrannavar       1.00      1.00      1.00         2\n",
      "      NaDisoza       1.00      0.88      0.93         8\n",
      "Narsimhamurthy       1.00      1.00      1.00         1\n",
      "      bhagavan       1.00      0.60      0.75         5\n",
      "chandrashekark       0.67      1.00      0.80         2\n",
      "       dodderi       0.78      0.88      0.82         8\n",
      "         gatti       1.00      1.00      1.00         2\n",
      "  hrudayashiva       0.40      0.50      0.44         4\n",
      "   ravibeliger       0.67      0.80      0.73         5\n",
      "    somashaker       1.00      1.00      1.00         5\n",
      "      srinatha       1.00      1.00      1.00         2\n",
      "          usha       1.00      0.80      0.89         5\n",
      "\n",
      "      accuracy                           0.84        49\n",
      "     macro avg       0.88      0.87      0.86        49\n",
      "  weighted avg       0.87      0.84      0.84        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppm_truValues=[]\n",
    "ppm_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    ppm_compress_train={}\n",
    "    ppm_concat={}\n",
    "    ppm_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    for author, data in Author_and_file.items():\n",
    "        ppm_compress_train[author] = pyppmd.compress(bytes(data, 'utf-8'))    \n",
    "        #file concatination\n",
    "        ppm_concat[author] = data+singleFile\n",
    "\n",
    "\n",
    "    #test file compress    \n",
    "    ppm_singleFileComp = pyppmd.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in ppm_concat.items():\n",
    "        ppm_concat_comp[i] = pyppmd.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "\n",
    "    ppm_cdm_values={}\n",
    "    for i,j in ppm_compress_train.items():\n",
    "        ppm_cdm_values[i] = (  len(ppm_concat_comp[i]) / ( len(ppm_compress_train[i])+len(ppm_singleFileComp))) \n",
    "        \n",
    "    known =''.join([i for i in singleAuthor if not i.isdigit()])   \n",
    "    ppm_truValues.append(known)\n",
    "    tp=next(iter(dict(sorted(ppm_cdm_values.items(), key=lambda item: item[1]))))\n",
    "    \n",
    "    pred = ''.join([i for i in tp if not i.isdigit()])\n",
    "    ppm_truPred.append(pred)\n",
    "    \n",
    "print(classification_report(ppm_truValues, ppm_truPred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
