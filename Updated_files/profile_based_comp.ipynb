{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile based compression method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lzw3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bcdff07818e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbz2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlzw3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lzw3'"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import string\n",
    "from scipy import sparse\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import bz2\n",
    "import gzip\n",
    "#import lzw3\n",
    "import zlib\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lzma\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training files reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Profile_Auth_File={}\n",
    "#basepath = 'C:/Users/RAVIKUMAR/Desktop/txt datsets-20210502T053858Z-001/txt datsets' \n",
    "basepath = \"C:/Users/RAVIKUMAR/Desktop/Profile_base_data/training/\"\n",
    "for dir_name in os.listdir(basepath):    \n",
    "    dir_path = os.path.join(basepath, dir_name)\n",
    "    if not os.path.isdir(dir_path):\n",
    "        continue    \n",
    "    with open(os.path.join(dir_path, dir_name+'.txt') , 'w', encoding='utf-8') as outfile:\n",
    "        files = []       \n",
    "        for file_name in os.listdir(dir_path):\n",
    "            if file_name.endswith('.txt'):\n",
    "                with open(os.path.join(dir_path, file_name), encoding='utf-8') as readfile:\n",
    "                    #files.append(file_name)\n",
    "                    files.append(readfile.read())\n",
    "        Profile_Auth_File[dir_name] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing file reading\n",
    "###### testing files concatinated and make it single profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tesing file reading\n",
    "#basepath = 'C:/Users/RAVIKUMAR/Desktop/txt datsets-20210502T053858Z-001/testing'\n",
    "testingpath = \"C:/Users/RAVIKUMAR/Desktop/Profile_base_data/testing/\"\n",
    "testing = {}\n",
    "\n",
    "# for f in os.listdir(testingpath):\n",
    "#     if f.endswith('.txt'):\n",
    "#         with open(os.path.join(basepath, f), encoding='utf-8') as testfile:\n",
    "#             testing[f] = testfile.read()\n",
    "\n",
    "\n",
    "# for dir_name in os.listdir(testingpath):    \n",
    "#     dir_path = os.path.join(testingpath, dir_name)\n",
    "#     if not os.path.isdir(dir_path):\n",
    "#         continue    \n",
    "#     with open(os.path.join(dir_path, dir_name+'.txt') , 'w', encoding='utf-8') as outfile:\n",
    "#         files = []       \n",
    "#         for file_name in os.listdir(dir_path):\n",
    "#             if file_name.endswith('.txt'):\n",
    "#                 with open(os.path.join(dir_path, file_name), encoding='utf-8') as readfile:\n",
    "#                     #files.append(file_name)\n",
    "#                     files.append(readfile.read())\n",
    "#         testing[dir_name] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_test = \"C:/Users/RAVIKUMAR/Desktop/Profile_base_data/test/\"\n",
    "test_authors = []\n",
    "for i in os.listdir(sp_test):\n",
    "    test_authors.append(i)\n",
    "at = pd.Series(test_authors)\n",
    "\n",
    "at.replace(r'(^Ra.*)' , 'Ravi belagere',regex=True, inplace = True)\n",
    "at.replace(r'(^BM.*)' , 'BM Ramesh',regex=True, inplace = True)\n",
    "at.replace(r'(^bm.*)' , 'BM Ramesh',regex=True, inplace = True)\n",
    "at.replace(r'(^Bh.*)', 'Bhagvan KN',regex=True, inplace = True)\n",
    "at.replace(r'(^bh.*)', 'Bhagvan KN',regex=True, inplace = True)\n",
    "at.replace(r'^Ch.*', 'Chandrashekar K' ,regex=True, inplace = True)\n",
    "at.replace(r'^ck.*', 'Chandrashekar K' ,regex=True, inplace = True)\n",
    "at.replace(r'(^Hr.*)' , 'Hrudayashiva',regex=True, inplace = True)\n",
    "at.replace(r'(^KG.*)' , 'KG Bhadrannavar',regex=True, inplace = True)\n",
    "at.replace(r'(^KT.*)', 'KT Gatti',regex=True, inplace = True)\n",
    "at.replace(r'(^MS.*)', 'MS Narsimhamurthy',regex=True, inplace = True)\n",
    "at.replace(r'(^ds.*)', 'NA Dsouza',regex=True, inplace = True)\n",
    "at.replace(r'(^So.*)' , 'Somashekar',regex=True, inplace = True)\n",
    "at.replace(r'(^Sri.*)' , 'Srinatha L',regex=True, inplace = True)\n",
    "at.replace(r'(^sd.*)', 'Sushrutha Dodderi',regex=True, inplace = True)\n",
    "at.replace(r'(^Sushrutha.*)', 'Sushrutha Dodderi',regex=True, inplace = True)\n",
    "at.replace(r'(^Us.*)', 'Usha P',regex=True, inplace = True)\n",
    "at.replace(r'(^us.*)', 'Usha P',regex=True, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing -- cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list=\"C:/Users/RAVIKUMAR/PycharmProjects/Authorship_Attribution_Instance/Data_2/new_stop_words.txt\"\n",
    "\n",
    "# removing stop words plus punctuation.\n",
    "\n",
    "with open(stop_words_list, encoding='utf-8') as file:\n",
    "    reader=file.read()\n",
    "    reader = [reader.split()]\n",
    "    stopword = sum(reader, [])\n",
    "#ss =\".,\"   \n",
    "sp = \"0123456789‘’\"\n",
    "def text_process(text):\n",
    "    nopunct = \"\".join([char for char in text if char not in string.punctuation+sp])\n",
    "    tokens = nltk.word_tokenize(nopunct)\n",
    "    nopunct = \" \".join([word for word in tokens if word not in stopword])\n",
    "    return nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "clean_data = {}\n",
    "for i, j in Profile_Auth_File.items():\n",
    "    clean_data[i]=text_process(str(j))\n",
    "#testing\n",
    "# clean_test={}\n",
    "# for i, j in testing.items():\n",
    "#     clean_test[i] = text_process(str(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### readig testing files indviduals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files =[]\n",
    "\n",
    "all_test_files = glob.glob('C:/Users/RAVIKUMAR/Desktop/Profile_base_data/test/*.txt')\n",
    "for i in all_test_files:\n",
    "    with open(i, encoding='utf-8') as read_files:\n",
    "        test_files.append(text_process(read_files.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df1 = pd.DataFrame()\n",
    "df[\"Authors\"] = Profile_Auth_File.keys()\n",
    "df[\"raw_concatinated_files\"] = Profile_Auth_File.values()\n",
    "df[\"clean_data\"] = clean_data.values()\n",
    "#df[\"testing_files\"] = clean_test.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing file method--- combine all files and make one profile\n",
    "# A=list(clean_test.values())\n",
    "# B=list(clean_test.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing file method 2--separate files\n",
    "A=list(test_files)\n",
    "B=list(at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i , j in clean_data.items():\n",
    "#     print(i, j)\n",
    "#     break\n",
    "# for i , j in zip(B, A):\n",
    "#     print(i, j)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Normalized Compressor Distance (NCD) <center>\n",
    "It uses general compressors to estimate the amount of shared\n",
    "information between two objects. The Normalized\n",
    "Compression Distance is defined as:\n",
    "\n",
    "$$\n",
    " NCD(x/y) = \\frac{\\ C(x/y)-min(C(x),C(y))}{max(C(x),C(y))}\n",
    "$$\n",
    "\n",
    "Where C(x) is the size of the compressed object x. If x = y,\n",
    "the NCD is approximately 0, as the full string y can be\n",
    "described in terms of previous strings found in x; if x and y\n",
    "share no common information the NCD is 1 + e, where e is a\n",
    "small quantity due to imperfections characterizing real\n",
    "compressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.25      0.40         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.18      1.00      0.30         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.16      1.00      0.27         3\n",
      "       Somashekar       0.67      0.67      0.67         3\n",
      "       Srinatha L       0.00      0.00      0.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.20        54\n",
      "        macro avg       0.15      0.22      0.13        54\n",
      "     weighted avg       0.14      0.20      0.11        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lzma_truValues=[]\n",
    "lzma_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    \n",
    "    singleAuthor=B[n]\n",
    "    #print(singleAuthor)\n",
    "    lzma_concat = {}\n",
    "    lzma_concat_comp ={}\n",
    "    lzma_compress_train={} \n",
    "\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in clean_data.items():\n",
    "        lzma_compress_train[author] = lzma.compress(bytes(data, 'utf-8'))\n",
    "        lzma_concat[author] = singleFile+data\n",
    "    #compress single file for testing     \n",
    "    lzma_singleFileComp = lzma.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in lzma_concat.items():\n",
    "        lzma_concat_comp[i] = lzma.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #calculate ncd values for each profile\n",
    "    lzma_ncd_values={}\n",
    "    for i,j in lzma_compress_train.items():\n",
    "        lzma_ncd_values[i] = (len(lzma_concat_comp[i]) - min(len(lzma_compress_train[i]), len(lzma_singleFileComp)))/max(len(lzma_compress_train[i]), len(lzma_singleFileComp))\n",
    "        \n",
    "    lzma_truValues.append(singleAuthor)\n",
    "   # print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(lzma_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    #print(\"predicted author: \",tp)\n",
    "    lzma_truPred.append(tp)\n",
    "print(classification_report(lzma_truValues, lzma_truPred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  BM Ramesh\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  BM Ramesh\n",
      "predicted author:  BM Ramesh\n",
      "given author:  BM Ramesh\n",
      "predicted author:  BM Ramesh\n",
      "given author:  BM Ramesh\n",
      "predicted author:  BM Ramesh\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Ravi belagere\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Ravi belagere\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Ravi belagere\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Ravi belagere\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Ravi belagere\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Ravi belagere\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Hrudayashiva\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Hrudayashiva\n",
      "predicted author:  Hrudayashiva\n",
      "given author:  Hrudayashiva\n",
      "predicted author:  Hrudayashiva\n",
      "given author:  KG Bhadrannavar\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KG Bhadrannavar\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Hrudayashiva\n",
      "given author:  KT Gatti\n",
      "predicted author:  Hrudayashiva\n",
      "given author:  MS Narsimhamurthy\n",
      "predicted author:  Ravi belagere\n",
      "given author:  MS Narsimhamurthy\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Ravi belagere\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Ravi belagere\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Ravi belagere\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Somashekar\n",
      "predicted author:  Somashekar\n",
      "given author:  Somashekar\n",
      "predicted author:  Somashekar\n",
      "given author:  Somashekar\n",
      "predicted author:  Somashekar\n",
      "given author:  Srinatha L\n",
      "predicted author:  Srinatha L\n",
      "given author:  Srinatha L\n",
      "predicted author:  Srinatha L\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Usha P\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Usha P\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Usha P\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Usha P\n",
      "predicted author:  Ravi belagere\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.75      0.86         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.56      1.00      0.71         5\n",
      "     Hrudayashiva       0.50      0.67      0.57         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.09      1.00      0.17         3\n",
      "       Somashekar       1.00      1.00      1.00         3\n",
      "       Srinatha L       1.00      1.00      1.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.33        54\n",
      "        macro avg       0.32      0.42      0.33        54\n",
      "     weighted avg       0.25      0.33      0.26        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bzip_truValues=[]\n",
    "\n",
    "bzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    bzip_compress_train={}\n",
    "    bzip_concat={}\n",
    "    bzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "    \n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in clean_data.items():\n",
    "        bzip_compress_train[author] = bz2.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        bzip_concat[author] = data+singleFile\n",
    "        \n",
    "\n",
    "\n",
    "    #compress single file for testing   \n",
    "    bzip_singleFileComp = bz2.compress(bytes(singleFile, 'utf-8'), compressionLevel)\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in bzip_concat.items():\n",
    "        bzip_concat_comp[i] = bz2.compress(bytes(j, \"utf-8\"), compressionLevel)\n",
    "\n",
    "\n",
    "    bzip_ncd_values={}\n",
    "    for i,j in bzip_compress_train.items():\n",
    "        bzip_ncd_values[i] = (len(bzip_concat_comp[i]) - min(len(bzip_compress_train[i]), len(bzip_singleFileComp)))/max(len(bzip_compress_train[i]), len(bzip_singleFileComp))\n",
    "    bzip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted( bzip_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    #print(\"predicted author: \",tp)\n",
    "    bzip_truPred.append(tp)\n",
    "    #print(bzip_ncd_values.items())\n",
    "print(classification_report(bzip_truValues, bzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gzip          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Bhagvan KN\n",
      "predicted author:  Ravi belagere\n",
      "given author:  BM Ramesh\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  BM Ramesh\n",
      "predicted author:  Ravi belagere\n",
      "given author:  BM Ramesh\n",
      "predicted author:  Somashekar\n",
      "given author:  BM Ramesh\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Chandrashekar K\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Ravi belagere\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  NA Dsouza\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Hrudayashiva\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Hrudayashiva\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Hrudayashiva\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KG Bhadrannavar\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  KG Bhadrannavar\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  KT Gatti\n",
      "predicted author:  Ravi belagere\n",
      "given author:  MS Narsimhamurthy\n",
      "predicted author:  Ravi belagere\n",
      "given author:  MS Narsimhamurthy\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Ravi belagere\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Ravi belagere\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Ravi belagere\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Somashekar\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Somashekar\n",
      "predicted author:  Somashekar\n",
      "given author:  Somashekar\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Srinatha L\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Srinatha L\n",
      "predicted author:  Ravi belagere\n",
      "given author:  Sushrutha Dodderi\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Usha P\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Usha P\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Usha P\n",
      "predicted author:  Chandrashekar K\n",
      "given author:  Usha P\n",
      "predicted author:  Ravi belagere\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       0.00      0.00      0.00         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.22      1.00      0.36         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.10      1.00      0.19         3\n",
      "       Somashekar       0.50      0.33      0.40         3\n",
      "       Srinatha L       0.00      0.00      0.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.17        54\n",
      "        macro avg       0.06      0.18      0.07        54\n",
      "     weighted avg       0.05      0.17      0.07        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gzip_truValues=[]\n",
    "gzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    gzip_compress_train={}\n",
    "    gzip_concat={}\n",
    "    gzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in clean_data.items():\n",
    "        gzip_compress_train[author] = gzip.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        gzip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    gzip_singleFileComp = gzip.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in gzip_concat.items():\n",
    "        gzip_concat_comp[i] = gzip.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    gzip_ncd_values={}\n",
    "    for i,j in gzip_compress_train.items():\n",
    "        gzip_ncd_values[i] = (len(gzip_concat_comp[i]) - min(len(gzip_compress_train[i]), len(gzip_singleFileComp)))/max(len(gzip_compress_train[i]), len(gzip_singleFileComp))\n",
    "        \n",
    "    gzip_truValues.append(singleAuthor)\n",
    "    \n",
    "  #  print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(gzip_ncd_values.items(), key=lambda item: item[1]))))\n",
    "   # print(\"predicted author: \",tp)\n",
    "\n",
    "    gzip_truPred.append(tp)\n",
    "    \n",
    "print(classification_report(gzip_truValues, gzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       0.00      0.00      0.00         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.17      1.00      0.29         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.14      1.00      0.24         3\n",
      "       Somashekar       0.33      0.33      0.33         3\n",
      "       Srinatha L       0.00      0.00      0.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.17        54\n",
      "        macro avg       0.05      0.18      0.07        54\n",
      "     weighted avg       0.04      0.17      0.06        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_truValues=[]\n",
    "zip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    zip_compress_train={}\n",
    "    zip_concat={}\n",
    "    zip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in clean_data.items():\n",
    "        zip_compress_train[author] = zlib.compress(bytes(data, 'utf-8'))\n",
    "        zip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    zip_singleFileComp = zlib.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in zip_concat.items():\n",
    "        zip_concat_comp[i] = zlib.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    zip_ncd_values={}\n",
    "    for i,j in zip_compress_train.items():\n",
    "        zip_ncd_values[i] = (len(zip_concat_comp[i]) - min(len(zip_compress_train[i]), len(zip_singleFileComp)))/max(len(zip_compress_train[i]), len(zip_singleFileComp))\n",
    "        \n",
    "    zip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(zip_ncd_values.items(), key=lambda item: item[1]))))\n",
    "    #print(\"predicted author: \",tp)\n",
    "\n",
    "    zip_truPred.append(tp)\n",
    "    \n",
    "print(classification_report(zip_truValues, zip_truPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         3\n",
      "           1       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.67         9\n",
      "   macro avg       0.75      0.75      0.67         9\n",
      "weighted avg       0.83      0.67      0.67         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = [1,0,1,0,0,1,1,1,1]\n",
    "p = [0,0,1,0,0,1,0,0,1]\n",
    "print(classification_report(g, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>Conditional Complexity of Compression (CCC)</center></h1><br>\n",
    "\n",
    "Conditional Complexity of Compression (CCC) proposed in The CCC of text y given text x is calculated by\n",
    "$$\n",
    "CCC(y/x) = |Sc|-|Xc|\n",
    "$$\n",
    "where <b>|xc| is the length of the compressed text x <br>\n",
    "The S is the concatenated text of xy</b><br>\n",
    "\n",
    "CCC approximates a more abstract\n",
    "Kolmogorov conditional complexity and measures adapts to\n",
    "patterns in the training text for better compressing the\n",
    "unknown text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.75      0.86         4\n",
      "       Bhagvan KN       0.36      1.00      0.53         5\n",
      "  Chandrashekar K       0.00      0.00      0.00         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.67      1.00      0.80         2\n",
      "         KT Gatti       0.42      1.00      0.59         5\n",
      "MS Narsimhamurthy       1.00      1.00      1.00         2\n",
      "        NA Dsouza       0.58      1.00      0.74         7\n",
      "    Ravi belagere       0.00      0.00      0.00         3\n",
      "       Somashekar       1.00      0.33      0.50         3\n",
      "       Srinatha L       1.00      1.00      1.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.60      0.75      0.67         4\n",
      "\n",
      "         accuracy                           0.56        54\n",
      "        macro avg       0.51      0.60      0.51        54\n",
      "     weighted avg       0.42      0.56      0.44        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lzma_truValues=[]\n",
    "lzma_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    \n",
    "    singleAuthor=B[n]\n",
    "    #print(singleAuthor)\n",
    "    lzma_concat = {}\n",
    "    lzma_concat_comp ={}\n",
    "    lzma_compress_train={} \n",
    "\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in clean_data.items():\n",
    "        lzma_compress_train[author] = lzma.compress(bytes(data, 'utf-8'))\n",
    "        lzma_concat[author] = singleFile+data\n",
    "    #compress single file for testing     \n",
    "    lzma_singleFileComp = lzma.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in lzma_concat.items():\n",
    "        lzma_concat_comp[i] = lzma.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #calculate ncd values for each profile\n",
    "    lzma_ccc_values={}\n",
    "    for i,j in lzma_compress_train.items():\n",
    "        lzma_ccc_values[i] = (len(lzma_concat_comp[i]) - len(lzma_compress_train[i]))\n",
    "        \n",
    "    lzma_truValues.append(singleAuthor)\n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(lzma_ccc_values.items(), key=lambda item: item[1]))))\n",
    "    #print(\"predicted author: \",tp)\n",
    "    lzma_truPred.append(tp)\n",
    "print(classification_report(lzma_truValues, lzma_truPred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.75      0.86         4\n",
      "       Bhagvan KN       0.26      1.00      0.42         5\n",
      "  Chandrashekar K       0.00      0.00      0.00         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.29      1.00      0.44         2\n",
      "         KT Gatti       0.42      1.00      0.59         5\n",
      "MS Narsimhamurthy       1.00      1.00      1.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.00      0.00      0.00         3\n",
      "       Somashekar       0.00      0.00      0.00         3\n",
      "       Srinatha L       1.00      1.00      1.00         2\n",
      "Sushrutha Dodderi       1.00      0.67      0.80         9\n",
      "           Usha P       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.52        54\n",
      "        macro avg       0.46      0.55      0.46        54\n",
      "     weighted avg       0.46      0.52      0.44        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bzip_truValues=[]\n",
    "\n",
    "bzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    bzip_compress_train={}\n",
    "    bzip_concat={}\n",
    "    bzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "    \n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in clean_data.items():\n",
    "        bzip_compress_train[author] = bz2.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        bzip_concat[author] = data+singleFile\n",
    "        \n",
    "\n",
    "\n",
    "    #compress single file for testing   \n",
    "    bzip_singleFileComp = bz2.compress(bytes(singleFile, 'utf-8'), compressionLevel)\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in bzip_concat.items():\n",
    "        bzip_concat_comp[i] = bz2.compress(bytes(j, \"utf-8\"), compressionLevel)\n",
    "\n",
    "\n",
    "    bzip_ccc_values={}\n",
    "    for i,j in bzip_compress_train.items():\n",
    "        bzip_ccc_values[i] = (len(bzip_concat_comp[i]) - len(bzip_compress_train[i]))\n",
    "    bzip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted( bzip_ccc_values.items(), key=lambda item: item[1]))))\n",
    "   # print(\"predicted author: \",tp)\n",
    "    bzip_truPred.append(tp)\n",
    "    #print(bzip_ncd_values.items())\n",
    "print(classification_report(bzip_truValues, bzip_truPred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Authors list: ['Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'BM Ramesh', 'BM Ramesh', 'BM Ramesh', 'BM Ramesh', 'Chandrashekar K', 'Chandrashekar K', 'Chandrashekar K', 'Chandrashekar K', 'Chandrashekar K', 'NA Dsouza', 'NA Dsouza', 'NA Dsouza', 'NA Dsouza', 'NA Dsouza', 'NA Dsouza', 'NA Dsouza', 'Hrudayashiva', 'Hrudayashiva', 'Hrudayashiva', 'KG Bhadrannavar', 'KG Bhadrannavar', 'KT Gatti', 'KT Gatti', 'KT Gatti', 'KT Gatti', 'KT Gatti', 'MS Narsimhamurthy', 'MS Narsimhamurthy', 'Ravi belagere', 'Ravi belagere', 'Ravi belagere', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Somashekar', 'Somashekar', 'Somashekar', 'Srinatha L', 'Srinatha L', 'Sushrutha Dodderi', 'Usha P', 'Usha P', 'Usha P', 'Usha P']\n",
      "\n",
      "Predicted list: ['Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'BM Ramesh', 'BM Ramesh', 'BM Ramesh', 'Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'KT Gatti', 'KT Gatti', 'KG Bhadrannavar', 'KG Bhadrannavar', 'Bhagvan KN', 'KG Bhadrannavar', 'Bhagvan KN', 'Bhagvan KN', 'Bhagvan KN', 'KT Gatti', 'Bhagvan KN', 'Bhagvan KN', 'KG Bhadrannavar', 'KG Bhadrannavar', 'KT Gatti', 'KT Gatti', 'KT Gatti', 'KT Gatti', 'KT Gatti', 'MS Narsimhamurthy', 'MS Narsimhamurthy', 'KT Gatti', 'KT Gatti', 'Bhagvan KN', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'KG Bhadrannavar', 'Sushrutha Dodderi', 'Sushrutha Dodderi', 'KG Bhadrannavar', 'Sushrutha Dodderi', 'Bhagvan KN', 'KT Gatti', 'KT Gatti', 'Srinatha L', 'Srinatha L', 'Bhagvan KN', 'Bhagvan KN', 'Usha P', 'Usha P', 'Usha P']\n"
     ]
    }
   ],
   "source": [
    "print(\"Known Authors list:\",bzip_truValues)\n",
    "print()\n",
    "print(\"Predicted list:\",bzip_truPred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.75      0.86         4\n",
      "       Bhagvan KN       0.33      1.00      0.50         5\n",
      "  Chandrashekar K       1.00      0.40      0.57         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.60      0.60      0.60         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       1.00      0.57      0.73         7\n",
      "    Ravi belagere       0.33      0.67      0.44         3\n",
      "       Somashekar       1.00      0.67      0.80         3\n",
      "       Srinatha L       0.29      1.00      0.44         2\n",
      "Sushrutha Dodderi       1.00      0.89      0.94         9\n",
      "           Usha P       0.50      0.25      0.33         4\n",
      "\n",
      "         accuracy                           0.59        54\n",
      "        macro avg       0.54      0.52      0.48        54\n",
      "     weighted avg       0.67      0.59      0.58        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gzip_truValues=[]\n",
    "gzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    gzip_compress_train={}\n",
    "    gzip_concat={}\n",
    "    gzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in clean_data.items():\n",
    "        gzip_compress_train[author] = gzip.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        gzip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    gzip_singleFileComp = gzip.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in gzip_concat.items():\n",
    "        gzip_concat_comp[i] = gzip.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    gzip_ccc_values={}\n",
    "    for i,j in gzip_compress_train.items():\n",
    "        gzip_ccc_values[i] = (len(gzip_concat_comp[i]) - len(gzip_compress_train[i]))\n",
    "        \n",
    "    gzip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(gzip_ccc_values.items(), key=lambda item: item[1]))))\n",
    "   # print(\"predicted author: \",tp)\n",
    "\n",
    "    gzip_truPred.append(tp)\n",
    "    \n",
    "print(classification_report(gzip_truValues, gzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.75      0.86         4\n",
      "       Bhagvan KN       0.33      1.00      0.50         5\n",
      "  Chandrashekar K       0.75      0.60      0.67         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.67      0.40      0.50         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.83      0.71      0.77         7\n",
      "    Ravi belagere       0.29      0.67      0.40         3\n",
      "       Somashekar       1.00      1.00      1.00         3\n",
      "       Srinatha L       0.33      1.00      0.50         2\n",
      "Sushrutha Dodderi       1.00      0.67      0.80         9\n",
      "           Usha P       1.00      0.25      0.40         4\n",
      "\n",
      "         accuracy                           0.59        54\n",
      "        macro avg       0.55      0.54      0.49        54\n",
      "     weighted avg       0.67      0.59      0.58        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_truValues=[]\n",
    "zip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    zip_compress_train={}\n",
    "    zip_concat={}\n",
    "    zip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in clean_data.items():\n",
    "        zip_compress_train[author] = zlib.compress(bytes(data, 'utf-8'))\n",
    "        zip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    zip_singleFileComp = zlib.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in zip_concat.items():\n",
    "        zip_concat_comp[i] = zlib.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    zip_ccc_values={}\n",
    "    for i,j in zip_compress_train.items():\n",
    "        zip_ccc_values[i] = (len(zip_concat_comp[i]) - len(zip_compress_train[i]))\n",
    "    zip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(zip_ccc_values.items(), key=lambda item: item[1]))))\n",
    "    #print(\"predicted author: \",tp)\n",
    "\n",
    "    zip_truPred.append(tp)\n",
    "    \n",
    "print(classification_report(zip_truValues, zip_truPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  <center> Compression Dissimilarity Measure (CDM)<center> \n",
    " Compression Dissimilarity Measure (CDM)\n",
    "For documents x and y, the compression dissimilarity\n",
    "measure is defined as:\n",
    "$$\n",
    "CDM (x/y) = [\\frac{C(xy)}{C(x)+C(y)}]\n",
    "$$\n",
    "Where C (x) is the size of the compressed object x, <br>\n",
    "C(y) is the size of the compressed object y,  <br>\n",
    "xy is the concatenation of x and y and  <br>\n",
    "C(xy) is the size of the compressed object xy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.75      0.86         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.26      1.00      0.42         5\n",
      "     Hrudayashiva       0.25      0.33      0.29         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.14      1.00      0.24         3\n",
      "       Somashekar       0.75      1.00      0.86         3\n",
      "       Srinatha L       1.00      1.00      1.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.31        54\n",
      "        macro avg       0.26      0.39      0.28        54\n",
      "     weighted avg       0.20      0.31      0.22        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lzma_truValues=[]\n",
    "lzma_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    \n",
    "    singleAuthor=B[n]\n",
    "    #print(singleAuthor)\n",
    "    lzma_concat = {}\n",
    "    lzma_concat_comp ={}\n",
    "    lzma_compress_train={} \n",
    "\n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in clean_data.items():\n",
    "        lzma_compress_train[author] = lzma.compress(bytes(data, 'utf-8'))\n",
    "        lzma_concat[author] = singleFile+data\n",
    "    #compress single file for testing     \n",
    "    lzma_singleFileComp = lzma.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in lzma_concat.items():\n",
    "        lzma_concat_comp[i] = lzma.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #calculate ncd values for each profile\n",
    "    lzma_cdm_values={}\n",
    "    for i,j in lzma_compress_train.items():\n",
    "        lzma_cdm_values[i] = (len(lzma_concat_comp[i]) / (len(lzma_compress_train[i])+len(lzma_singleFileComp)) )\n",
    "    lzma_truValues.append(singleAuthor)\n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(lzma_cdm_values.items(), key=lambda item: item[1]))))\n",
    "   # print(\"predicted author: \",tp)\n",
    "    lzma_truPred.append(tp)\n",
    "print(classification_report(lzma_truValues, lzma_truPred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       1.00      0.75      0.86         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.56      1.00      0.71         5\n",
      "     Hrudayashiva       0.33      0.67      0.44         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.10      1.00      0.18         3\n",
      "       Somashekar       0.75      1.00      0.86         3\n",
      "       Srinatha L       1.00      1.00      1.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.33        54\n",
      "        macro avg       0.29      0.42      0.31        54\n",
      "     weighted avg       0.23      0.33      0.25        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bzip_truValues=[]\n",
    "\n",
    "bzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    bzip_compress_train={}\n",
    "    bzip_concat={}\n",
    "    bzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "    \n",
    "    #compress each file \n",
    "    #concatinate each file with testing file---text data file not compressed\n",
    "    for author, data in clean_data.items():\n",
    "        bzip_compress_train[author] = bz2.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        bzip_concat[author] = data+singleFile\n",
    "        \n",
    "\n",
    "\n",
    "    #compress single file for testing   \n",
    "    bzip_singleFileComp = bz2.compress(bytes(singleFile, 'utf-8'), compressionLevel)\n",
    "\n",
    "    #compress concatinated file \n",
    "    for i,j in bzip_concat.items():\n",
    "        bzip_concat_comp[i] = bz2.compress(bytes(j, \"utf-8\"), compressionLevel)\n",
    "\n",
    "\n",
    "    bzip_cdm_values={}\n",
    "    for i,j in bzip_compress_train.items():\n",
    "        bzip_cdm_values[i] = (len(bzip_concat_comp[i]) / (len(bzip_compress_train[i])+len(bzip_singleFileComp)) )\n",
    "    bzip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted( bzip_cdm_values.items(), key=lambda item: item[1]))))\n",
    "   # print(\"predicted author: \",tp)\n",
    "    bzip_truPred.append(tp)\n",
    "    #print(bzip_ncd_values.items())\n",
    "print(classification_report(bzip_truValues, bzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       0.00      0.00      0.00         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.28      1.00      0.43         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.09      1.00      0.17         3\n",
      "       Somashekar       0.33      0.33      0.33         3\n",
      "       Srinatha L       0.00      0.00      0.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.17        54\n",
      "        macro avg       0.05      0.18      0.07        54\n",
      "     weighted avg       0.05      0.17      0.07        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gzip_truValues=[]\n",
    "gzip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    gzip_compress_train={}\n",
    "    gzip_concat={}\n",
    "    gzip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in clean_data.items():\n",
    "        gzip_compress_train[author] = gzip.compress(bytes(data, 'utf-8'), compressionLevel)\n",
    "        gzip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    gzip_singleFileComp = gzip.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in gzip_concat.items():\n",
    "        gzip_concat_comp[i] = gzip.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    gzip_cdm_values={}\n",
    "    for i,j in gzip_compress_train.items():\n",
    "        gzip_cdm_values[i] = (len(gzip_concat_comp[i]) / (len(gzip_compress_train[i])+len(gzip_singleFileComp)) )\n",
    "        \n",
    "    gzip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(gzip_cdm_values.items(), key=lambda item: item[1]))))\n",
    "   # print(\"predicted author: \",tp)\n",
    "\n",
    "    gzip_truPred.append(tp)\n",
    "    \n",
    "print(classification_report(gzip_truValues, gzip_truPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        BM Ramesh       0.00      0.00      0.00         4\n",
      "       Bhagvan KN       0.00      0.00      0.00         5\n",
      "  Chandrashekar K       0.21      1.00      0.34         5\n",
      "     Hrudayashiva       0.00      0.00      0.00         3\n",
      "  KG Bhadrannavar       0.00      0.00      0.00         2\n",
      "         KT Gatti       0.00      0.00      0.00         5\n",
      "MS Narsimhamurthy       0.00      0.00      0.00         2\n",
      "        NA Dsouza       0.00      0.00      0.00         7\n",
      "    Ravi belagere       0.11      1.00      0.20         3\n",
      "       Somashekar       0.33      0.33      0.33         3\n",
      "       Srinatha L       0.00      0.00      0.00         2\n",
      "Sushrutha Dodderi       0.00      0.00      0.00         9\n",
      "           Usha P       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.17        54\n",
      "        macro avg       0.05      0.18      0.07        54\n",
      "     weighted avg       0.04      0.17      0.06        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_truValues=[]\n",
    "zip_truPred=[]\n",
    "for number in range(len(A)):\n",
    "    \n",
    "    n=number\n",
    "    singleFile=A[n]\n",
    "    singleAuthor=B[n] \n",
    "    \n",
    "    zip_compress_train={}\n",
    "    zip_concat={}\n",
    "    zip_concat_comp={}\n",
    "    compressionLevel=9\n",
    "\n",
    "    #each file compress\n",
    "    #concatinate with test file\n",
    "    for author, data in clean_data.items():\n",
    "        zip_compress_train[author] = zlib.compress(bytes(data, 'utf-8'))\n",
    "        zip_concat[author] = data+singleFile\n",
    "\n",
    "    #test file compress\n",
    "    zip_singleFileComp = zlib.compress(bytes(singleFile, 'utf-8'))\n",
    "\n",
    "    #compress concatinated files\n",
    "    for i,j in zip_concat.items():\n",
    "        zip_concat_comp[i] = zlib.compress(bytes(j, \"utf-8\"))\n",
    "\n",
    "    #compute ncd    \n",
    "    zip_cdm_values={}\n",
    "    for i,j in zip_compress_train.items():\n",
    "        zip_cdm_values[i] = (len(zip_concat_comp[i]) / (len(zip_compress_train[i])+len(zip_singleFileComp)) )\n",
    "    zip_truValues.append(singleAuthor)\n",
    "    \n",
    "    #print(\"given author: \",singleAuthor)\n",
    "    tp=next(iter(dict(sorted(zip_cdm_values.items(), key=lambda item: item[1]))))\n",
    "    #print(\"predicted author: \",tp)\n",
    "\n",
    "    zip_truPred.append(tp)\n",
    "    \n",
    "print(classification_report(zip_truValues, zip_truPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "PycharmProjects/Compression_model/profile_based_comp.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
